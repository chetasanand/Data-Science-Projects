{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2062,
     "status": "ok",
     "timestamp": 1666051861823,
     "user": {
      "displayName": "Chetas Anand",
      "userId": "08994943578146984733"
     },
     "user_tz": 420
    },
    "id": "XGeQNnMzNbvF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vecstack\n",
      "  Downloading vecstack-0.4.0.tar.gz (18 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from vecstack) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from vecstack) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from vecstack) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (2.2.0)\n",
      "Building wheels for collected packages: vecstack\n",
      "  Building wheel for vecstack (setup.py): started\n",
      "  Building wheel for vecstack (setup.py): finished with status 'done'\n",
      "  Created wheel for vecstack: filename=vecstack-0.4.0-py3-none-any.whl size=19877 sha256=be7984e7f811398b992164d2f69b6c652d64b448b52680d2e962ee91beb6a5b3\n",
      "  Stored in directory: c:\\users\\lenovo pro\\appdata\\local\\pip\\cache\\wheels\\7e\\ee\\d6\\47cb94a403bc544de1433986e5530d6b0498021098fbe43aa1\n",
      "Successfully built vecstack\n",
      "Installing collected packages: vecstack\n",
      "Successfully installed vecstack-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Downloading scikit_learn-1.1.2-cp39-cp39-win_amd64.whl (7.4 MB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lenovo pro\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.7.3)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed imbalanced-learn-0.9.1 scikit-learn-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score #works\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter #for Smote, \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tbBm6DvXNgl_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65000, 596)\n",
      "(173836, 596)\n",
      "   CoverageField11A  CoverageField11B  CoverageField1A  CoverageField1B  \\\n",
      "0                 2                 1               17               23   \n",
      "1                 5                 9                6                8   \n",
      "2                 4                 6                7               12   \n",
      "3                15                23                3                2   \n",
      "4                 4                 6                8               13   \n",
      "\n",
      "   CoverageField2A  CoverageField2B  CoverageField3A  CoverageField3B  \\\n",
      "0               17               23               15               22   \n",
      "1                6                8                5                7   \n",
      "2                7               12                6               10   \n",
      "3                3                2                2                2   \n",
      "4                8               13                7               11   \n",
      "\n",
      "   CoverageField4A  CoverageField4B  ...  PropertyField38_N  \\\n",
      "0               16               22  ...                  1   \n",
      "1                5                8  ...                  1   \n",
      "2                7               11  ...                  1   \n",
      "3                3                2  ...                  1   \n",
      "4                7               13  ...                  1   \n",
      "\n",
      "   PropertyField38_Y  GeographicField63_   GeographicField63_N  \\\n",
      "0                  0                    0                    1   \n",
      "1                  0                    0                    1   \n",
      "2                  0                    0                    1   \n",
      "3                  0                    0                    1   \n",
      "4                  0                    0                    1   \n",
      "\n",
      "   GeographicField63_Y  GeographicField64_CA  GeographicField64_IL  \\\n",
      "0                    0                     1                     0   \n",
      "1                    0                     0                     0   \n",
      "2                    0                     0                     0   \n",
      "3                    0                     0                     0   \n",
      "4                    0                     0                     1   \n",
      "\n",
      "   GeographicField64_NJ  GeographicField64_TX  QuoteConversion_Flag  \n",
      "0                     0                     0                     0  \n",
      "1                     1                     0                     0  \n",
      "2                     1                     0                     0  \n",
      "3                     0                     1                     0  \n",
      "4                     0                     0                     0  \n",
      "\n",
      "[5 rows x 596 columns]\n"
     ]
    }
   ],
   "source": [
    "trainfile = r'C:/Users/LENOVO PRO/ASU/CIS 508/Assign_03/RevisedHomesiteTrain1.csv'\n",
    "train_data = pd.read_csv(trainfile)\n",
    "\n",
    "#train_data = pd.read_csv(\"C:/Users/admin/Downloads/NewHomesiteTrain.csv\")\n",
    "\n",
    "\n",
    "testfile = r'C:/Users/LENOVO PRO/ASU/CIS 508/Assign_03/RevisedHomesiteTest1.csv'\n",
    "test_data = pd.read_csv(testfile)\n",
    "\n",
    "#test_data = pd.read_csv(\"C:/Users/admin/Downloads/NewHomesiteTest.csv\")\n",
    "\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65000,)\n",
      "(65000, 595)\n",
      "(173836, 595)\n",
      "0    52738\n",
      "1    12262\n",
      "Name: QuoteConversion_Flag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y1_train=train_data[\"QuoteConversion_Flag\"]\n",
    "X1_train=train_data.iloc[:, :-1].copy()\n",
    "X1_test=test_data.iloc[:, :-1].copy()\n",
    "print(y1_train.shape)\n",
    "print(X1_train.shape)\n",
    "print(X1_test.shape)\n",
    "\n",
    "print(train_data['QuoteConversion_Flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52000, 595)\n",
      "(52000,)\n",
      "(13000, 595)\n",
      "(13000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X1_train, y1_train, test_size=0.2, random_state=1)\n",
    "X_train, X_test, y_train, y_test\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________\n",
      "SMOTE\n",
      "\n",
      "Original dataset shape Counter({0: 52738, 1: 12262})\n",
      "Resampled dataset shape Counter({0: 42133, 1: 42133})\n",
      "(84266, 595)\n",
      "(84266,)\n"
     ]
    }
   ],
   "source": [
    "print(\"___________________________________________________________________\\nSMOTE\\n\")\n",
    "print('Original dataset shape %s' % Counter(y1_train))\n",
    "sm = SMOTE(sampling_strategy=1)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "print(X_res.shape)\n",
    "print(y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score (training) for Decision Tree:0.896712\n",
      "Confusion Matrix for Decision Tree\n",
      "[[9913  642]\n",
      " [ 676 1769]]\n",
      "Printing the precision and recall, among other metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     10555\n",
      "           1       0.73      0.72      0.73      2445\n",
      "\n",
      "    accuracy                           0.90     13000\n",
      "   macro avg       0.83      0.83      0.83     13000\n",
      "weighted avg       0.90      0.90      0.90     13000\n",
      "\n",
      "[0.7856183  0.7939771  0.79367961 0.79282478 0.79712444]\n"
     ]
    }
   ],
   "source": [
    "#Construct Decision Tree Model \n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_split=90, max_depth=9)\n",
    "clf.fit(X_res, y_res)\n",
    "clf_predict=clf.predict(X_test)\n",
    "print(\"accuracy Score (training) for Decision Tree:{0:6f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Confusion Matrix for Decision Tree\")\n",
    "print(confusion_matrix(y_test,clf_predict))\n",
    "\n",
    "print('Printing the precision and recall, among other metrics')\n",
    "print(metrics.classification_report(y_test, clf_predict))\n",
    "clf_cv_score = cross_val_score(clf, X_train,y_train, cv=5, scoring=\"balanced_accuracy\")\n",
    "print(clf_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 50, 'max_depth': 9}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [216]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m clf_predict \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy Score (training) after hypertuning for Decision Tree:\u001b[39m\u001b[38;5;132;01m{0:6f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(clf\u001b[38;5;241m.\u001b[39mscore(\u001b[43mX_test1\u001b[49m,y_test)))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix after hypertuning for Decision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test,clf_predict))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test1' is not defined"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning done for decision tree classifier\n",
    "parameters={'min_samples_split' : range(10,100,10),'max_depth': range(1,20,2)}\n",
    "clf_random = RandomizedSearchCV(clf,parameters,n_iter=15)\n",
    "clf_random.fit(X_train, y_train)\n",
    "grid_parm=clf_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the DecisionTreeClassifier \n",
    "clf = DecisionTreeClassifier(**grid_parm)\n",
    "clf.fit(X_train,y_train)\n",
    "clf_predict = clf.predict(X_test)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for Decision Tree:{0:6f}\".format(clf.score(X_test1,y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for Decision Tree\")\n",
    "print(confusion_matrix(y_test,clf_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,clf_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "clf_cv_score = cross_val_score(clf, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(clf_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Decision Tree: \",clf_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Random Forest Model\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_predict=rfc.predict(X_test)\n",
    "print(\"accuracy Score (training) for RandomForest:{0:6f}\".format(rfc.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix for Random Forest:\")\n",
    "print(confusion_matrix(y_test,rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for random forest classifier\n",
    "rfc_random = RandomizedSearchCV(rfc,parameters,n_iter=15)\n",
    "rfc_random.fit(X_train1, y_train)\n",
    "grid_parm_rfc=rfc_random.best_params_\n",
    "print(grid_parm_rfc)\n",
    "\n",
    "#Construct Random Forest with best parameters\n",
    "rfc= RandomForestClassifier(**grid_parm_rfc)\n",
    "rfc.fit(X_train1,y_train)\n",
    "rfc_predict = rfc.predict(X_test1)\n",
    "\n",
    "print(\"accuracy Score (training) after hypertuning for Random Forest:{0:6f}\".format(rfc.score(X_test1,y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for Random Forest:\")\n",
    "print(confusion_matrix(y_test,rfc_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,rfc_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "rfc_cv_score = cross_val_score(rfc, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \",rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct MultiLayer Perceptron Model\n",
    "\n",
    "mlp = MLPClassifier(max_iter=100)\n",
    "mlp.fit(X1_train, y1_train)\n",
    "mlp_predict=mlp.predict(X1_test)\n",
    "print(\"accuracy Score (training) for MultiLayer Perceptron:{0:6f}\".format(mlp.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix for MultiLayer Perceptron:\")\n",
    "print(confusion_matrix(y_test,mlp_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning done for MultiLayer Perceptron classifier\n",
    "\n",
    "#parameters = {'hidden_layer_sizes':[(10,), (20,)], 'activation':['tanh', 'relu'], 'solver':['sgd', 'adam'], 'alpha': [0.0001, 0.05], 'learning_rate':['constant', 'adaptive']}\n",
    "#parameters = {'hidden_layer_sizes':[(10,5), (20,5)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive']}\n",
    "parameters = {'hidden_layer_sizes':[(10,5,3), (20,7,3)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive'], 'max_iter' :[100, 150]}\n",
    "#parameters = {'hidden_layer_sizes':[(10,), (15,), (10,5), (20,7,3)]}\n",
    "\n",
    "mlp_random = RandomizedSearchCV(mlp,parameters,n_iter=15)\n",
    "mlp_random.fit(X_train1, y_train)\n",
    "grid_parm=mlp_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
    "mlp = MLPClassifier(**grid_parm)\n",
    "mlp.fit(X_train1,y_train)\n",
    "mlp_predict = mlp.predict(X_test1)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for MultiLayer Perceptron:{0:6f}\".format(mlp.score(X_test1,y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for MultiLayer Perceptron\")\n",
    "print(confusion_matrix(y_test,mlp_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,mlp_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "mlp_cv_score = cross_val_score(mlp, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(mlp_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - MultiLayer Perceptron: \",mlp_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct K-Nearest Neighbor Model\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "neigh_predict=neigh.predict(X_test)\n",
    "print(\"accuracy Score (training) for KNeighborsClassifier:{0:6f}\".format(neigh.score(X_test,y_test)))\n",
    "print(\"Confusion Matrix for KNeighborsClassifier:\")\n",
    "print(confusion_matrix(y_test,neigh_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning done for K-Nearest Neighbor classifier\n",
    "\n",
    "parameters = {'n_neighbors':[3,5,7,9,11], 'weights':['uniform', 'distance'], 'p':[1,2]}\n",
    "\n",
    "\n",
    "neigh_random = RandomizedSearchCV(neigh,parameters,n_iter=15)\n",
    "neigh_random.fit(X_train1, y_train)\n",
    "grid_parm=neigh_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
    "neigh = KNeighborsClassifier(**grid_parm)\n",
    "neigh.fit(X_train1,y_train)\n",
    "neigh_predict = neigh.predict(X_test1)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for KNeighborsClassifier:{0:6f}\".format(neigh.score(X_test1,y_test)))\n",
    "print(\"Confusion Matrix after hypertuning for KNeighborsClassifier\")\n",
    "print(confusion_matrix(y_test,neigh_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,neigh_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "neigh_cv_score = cross_val_score(neigh, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(neigh_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - KNeighborsClassifier: \",neigh_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Linear Support Vector Machine Model\n",
    "from sklearn.svm import LinearSVC \n",
    "linsvm = LinearSVC(max_iter=300) \n",
    "linsvm.fit(X1_train, y1_train) \n",
    "linsvm_predict=linsvm.predict(X1_test) \n",
    "# print(\"accuracy Score (training) for Linear SVM Classifier:{0:6f}\".format(linsvm.score(X_test,y_test))) \n",
    "# print(\"Confusion Matrix for Linear SVM Classifier:\") \n",
    "# print(confusion_matrix(y_test,linsvm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________\n",
      "SMOTE\n",
      "\n",
      "Original dataset shape Counter({0: 42133, 1: 9867})\n",
      "Resampled dataset shape Counter({0: 42133, 1: 42133})\n",
      "(84266, 595)\n",
      "(84266,)\n"
     ]
    }
   ],
   "source": [
    "print(\"___________________________________________________________________\\nSMOTE\\n\")\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "sm = SMOTE(sampling_strategy=1)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "print(X_res.shape)\n",
    "print(y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________\n",
      "Ensemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\n",
      "\n",
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.71728295]\n",
      "    fold  1:  [0.71557412]\n",
      "    fold  2:  [0.72078230]\n",
      "    fold  3:  [0.71598785]\n",
      "    ----\n",
      "    MEAN:     [0.71740681] + [0.00204826]\n",
      "    FULL:     [0.71740678]\n",
      "\n",
      "model  1:     [MLPClassifier]\n",
      "    fold  0:  [0.87046091]\n",
      "    fold  1:  [0.87648930]\n",
      "    fold  2:  [0.63818475]\n",
      "    fold  3:  [0.87909428]\n",
      "    ----\n",
      "    MEAN:     [0.81605731] + [0.10274250]\n",
      "    FULL:     [0.81605867]\n",
      "\n",
      "model  2:     [LinearSVC]\n",
      "    fold  0:  [0.57540229]\n",
      "    fold  1:  [0.61489533]\n",
      "    fold  2:  [0.56441660]\n",
      "    fold  3:  [0.57239153]\n",
      "    ----\n",
      "    MEAN:     [0.58177644] + [0.01953799]\n",
      "    FULL:     [0.58177675]\n",
      "\n",
      "model  3:     [RandomForestClassifier]\n",
      "    fold  0:  [0.93919400]\n",
      "    fold  1:  [0.94109270]\n",
      "    fold  2:  [0.93952340]\n",
      "    fold  3:  [0.93909617]\n",
      "    ----\n",
      "    MEAN:     [0.93972657] + [0.00080446]\n",
      "    FULL:     [0.93972658]\n",
      "\n",
      "model  4:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.91892533]\n",
      "    fold  1:  [0.91716903]\n",
      "    fold  2:  [0.92167474]\n",
      "    fold  3:  [0.91773474]\n",
      "    ----\n",
      "    MEAN:     [0.91887596] + [0.00173577]\n",
      "    FULL:     [0.91887594]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"___________________________________________________________________________________________\\nEnsemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\\n\")\n",
    "\n",
    "models = [ KNeighborsClassifier(), MLPClassifier(), LinearSVC(), RandomForestClassifier(), DecisionTreeClassifier() ]\n",
    "      \n",
    "S_Train, S_Test = stacking(models,                   \n",
    "                           X_res, y_res, X_test,   \n",
    "                           regression=False, \n",
    "     \n",
    "                           mode='oof_pred_bag', \n",
    "       \n",
    "                           needs_proba=False,\n",
    "         \n",
    "                           save_dir=None, \n",
    "            \n",
    "                           metric=accuracy_score, \n",
    "    \n",
    "                           n_folds=4, \n",
    "                 \n",
    "                           stratified=True,\n",
    "            \n",
    "                           shuffle=True,  \n",
    "            \n",
    "                           random_state=0,    \n",
    "         \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score for ensemble methods: [0.90146154]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "    \n",
    "model = model.fit(S_Train, y_res)\n",
    "y_pred = model.predict(S_Test)\n",
    "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 33, 'max_depth': 7, 'criterion': 'entropy'}\n",
      "accuracy Score (training) after hypertuning for Decision Tree:0.942195\n",
      "Confusion Matrix after hypertuning for Decision Tree\n",
      "[[10399   206]\n",
      " [ 1075  1320]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     10605\n",
      "           1       0.87      0.55      0.67      2395\n",
      "\n",
      "    accuracy                           0.90     13000\n",
      "   macro avg       0.89      0.77      0.81     13000\n",
      "weighted avg       0.90      0.90      0.89     13000\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.91423593 0.91703269 0.97036035 0.99651217 0.9961229  0.9949693\n",
      " 0.99640615 0.9966443  0.99656951 0.997648  ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Decision Tree:  0.9776501291962225\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning done for decision tree classifier\n",
    "parameters={'min_samples_split' : range(1,50,2),'max_depth': \n",
    "            range(5,20,1),'criterion':['gini','entropy']}\n",
    "clf_random = RandomizedSearchCV(clf,parameters,n_iter=15)\n",
    "clf_random.fit(S_Train, y_res)\n",
    "grid_parm=clf_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the DecisionTreeClassifier \n",
    "clf = DecisionTreeClassifier(**grid_parm)\n",
    "clf.fit(S_Train, y_res)\n",
    "clf_predict1 = clf.predict(S_Test)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for Decision Tree:{0:6f}\".format(clf.score(S_Train, y_res)))\n",
    "print(\"Confusion Matrix after hypertuning for Decision Tree\")\n",
    "print(confusion_matrix(y_test,clf_predict1))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,clf_predict1))\n",
    "\n",
    "#get cross-validation report\n",
    "clf_cv_score = cross_val_score(clf, S_Train, y_res, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(clf_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Decision Tree: \",clf_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score for ensemble methods: [0.90138462]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "    \n",
    "model = model.fit(S_Train, y_res)\n",
    "y_pred = model.predict(S_Test)\n",
    "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'hidden_layer_sizes': (10, 5, 3), 'learning_rate': 'constant', 'max_iter': 150}\n",
      "accuracy Score (training) after hypertuning for MultiLayer Perceptron:0.941791\n",
      "Confusion Matrix after hypertuning for MultiLayer Perceptron\n",
      "[[10388   217]\n",
      " [ 1074  1321]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     10605\n",
      "           1       0.86      0.55      0.67      2395\n",
      "\n",
      "    accuracy                           0.90     13000\n",
      "   macro avg       0.88      0.77      0.81     13000\n",
      "weighted avg       0.90      0.90      0.89     13000\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.91436075 0.91682236 0.97038063 0.99651437 0.99613286 0.99496845\n",
      " 0.99637573 0.99660132 0.99637503 0.99768102]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - MultiLayer Perceptron:  0.9776212505758057\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning done for MultiLayer Perceptron classifier\n",
    "\n",
    "#parameters = {'hidden_layer_sizes':[(10,), (20,)], 'activation':['tanh', 'relu'], 'solver':['sgd', 'adam'], 'alpha': [0.0001, 0.05], 'learning_rate':['constant', 'adaptive']}\n",
    "#parameters = {'hidden_layer_sizes':[(10,5), (20,5)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive']}\n",
    "parameters = {'hidden_layer_sizes':[(10,5,3), (20,7,3)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive'], 'max_iter' :[100, 150]}\n",
    "#parameters = {'hidden_layer_sizes':[(10,), (15,), (10,5), (20,7,3)]}\n",
    "\n",
    "mlp_grid = GridSearchCV(mlp,parameters)\n",
    "mlp_grid.fit(S_Train, y_res)\n",
    "grid_parm=mlp_grid.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
    "mlp = MLPClassifier(**grid_parm)\n",
    "mlp.fit(S_Train, y_res)\n",
    "mlp_predict = mlp.predict(S_Test)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for MultiLayer Perceptron:{0:6f}\".format(mlp.score(S_Train, y_res)))\n",
    "print(\"Confusion Matrix after hypertuning for MultiLayer Perceptron\")\n",
    "print(confusion_matrix(y_test,mlp_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,mlp_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "mlp_cv_score = cross_val_score(mlp, S_Train, y_res, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(mlp_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - MultiLayer Perceptron: \",mlp_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score for ensemble methods: [0.90253846]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "    \n",
    "model = model.fit(S_Train, y_res)\n",
    "y_pred = model.predict(S_Test)\n",
    "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'distance', 'p': 1, 'n_neighbors': 7}\n",
      "accuracy Score (training) after hypertuning for KNeighborsClassifier:0.938053\n",
      "Confusion Matrix after hypertuning for KNeighborsClassifier\n",
      "[[10401   204]\n",
      " [ 1059  1336]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     10605\n",
      "           1       0.87      0.56      0.68      2395\n",
      "\n",
      "    accuracy                           0.90     13000\n",
      "   macro avg       0.89      0.77      0.81     13000\n",
      "weighted avg       0.90      0.90      0.89     13000\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.51198679 0.86653724 0.95476071 0.99025214 0.99261794 0.99213663\n",
      " 0.99359597 0.99292938 0.99251517 0.9932488 ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - KNeighborsClassifier:  0.9280580772653385\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning done for K-Nearest Neighbor classifier\n",
    "\n",
    "parameters = {'n_neighbors':[3,5,7,9,11], 'weights':['uniform', 'distance'], 'p':[1,2]}\n",
    "\n",
    "\n",
    "neigh_random = RandomizedSearchCV(neigh,parameters,n_iter=15)\n",
    "neigh_random.fit(S_Train, y_res)\n",
    "grid_parm=neigh_random.best_params_\n",
    "print(grid_parm)\n",
    "\n",
    "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
    "neigh = KNeighborsClassifier(**grid_parm)\n",
    "neigh.fit(S_Train, y_res)\n",
    "neigh_predict = neigh.predict(S_Test)\n",
    "\n",
    "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
    "print(\"accuracy Score (training) after hypertuning for KNeighborsClassifier:{0:6f}\".format(neigh.score(S_Train, y_res)))\n",
    "print(\"Confusion Matrix after hypertuning for KNeighborsClassifier\")\n",
    "print(confusion_matrix(y_test,neigh_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,neigh_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "neigh_cv_score = cross_val_score(neigh, S_Train, y_res, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(neigh_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - KNeighborsClassifier: \",neigh_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 26, 'min_samples_leaf': 9, 'max_features': 56, 'max_depth': 7}\n",
      "accuracy Score (training) after hypertuning for Random Forest:0.942183\n",
      "Confusion Matrix after hypertuning for Random Forest:\n",
      "[[10399   206]\n",
      " [ 1076  1319]]\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     10605\n",
      "           1       0.86      0.55      0.67      2395\n",
      "\n",
      "    accuracy                           0.90     13000\n",
      "   macro avg       0.89      0.77      0.81     13000\n",
      "weighted avg       0.90      0.90      0.89     13000\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.91430679 0.91703021 0.97036761 0.99651498 0.99612075 0.99496902\n",
      " 0.99640615 0.99662537 0.99656951 0.997648  ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.9776558402704543\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning for random forest classifier\n",
    "rand_parameters={'min_samples_leaf' : range(1,10,1),'max_depth': \n",
    "            range(5,10,1),'max_features':range(30,60,2),'n_estimators':range(8,28,2)}\n",
    "\n",
    "rfc_random = RandomizedSearchCV(rfc,rand_parameters,n_iter=15)\n",
    "rfc_random.fit(S_Train, y_res)\n",
    "grid_parm_rfc=rfc_random.best_params_\n",
    "print(grid_parm_rfc)\n",
    "\n",
    "#Construct Random Forest with best parameters\n",
    "rfc= RandomForestClassifier(**grid_parm_rfc)\n",
    "rfc.fit(S_Train, y_res)\n",
    "rfc_predict = rfc.predict(S_Test)\n",
    "\n",
    "print(\"accuracy Score (training) after hypertuning for Random Forest:{0:6f}\".format(rfc.score(S_Train, y_res)))\n",
    "print(\"Confusion Matrix after hypertuning for Random Forest:\")\n",
    "print(confusion_matrix(y_test,rfc_predict))\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,rfc_predict))\n",
    "\n",
    "#get cross-validation report\n",
    "rfc_cv_score = cross_val_score(rfc, S_Train, y_res, cv=10, scoring=\"roc_auc\")\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \",rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhEnfchcYjVW9ABkOaY1It",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
